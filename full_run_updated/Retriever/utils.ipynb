{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3b18d-a97b-469a-97c2-1f2d98552911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def evaluation(key_ref, corpus_scores, query_labels, dataset_name):\n",
    "    recall_threshold = [1, 5, 10]\n",
    "    recall_results = [0] * len(recall_threshold)\n",
    "    \n",
    "    dataset_parts = {\n",
    "        \"perspectrum\": [\"support\", \"undermine\", \"general\"],\n",
    "        \"agnews\": [\"subtopic\", \"location\"],\n",
    "        \"story\": [\"analogy\", \"entity\"],\n",
    "        \"ambigqa\": [\"perspective\"],\n",
    "        \"allsides\": [\"left\", \"right\", \"center\"],\n",
    "        \"exfever\": [\"SUPPORT\", \"REFUTE\", \"NOT ENOUGH INFO\"]\n",
    "    }\n",
    "    \n",
    "    parts = dataset_parts.get(dataset_name, [\"none\"])\n",
    "    parts_size = [0] * len(parts)\n",
    "    \n",
    "    for lb in query_labels:\n",
    "        parts_size[parts.index(lb)] += 1\n",
    "            \n",
    "    partial_recall_results = [[0] * len(recall_threshold) for _ in range(len(parts))]\n",
    "    \n",
    "    for k, v in key_ref.items():\n",
    "        for j, thresh in enumerate(recall_threshold):\n",
    "            ranked_scores = (-np.array(corpus_scores[int(k)])).argsort()[:thresh]\n",
    "            indicator = any(int(index) in ranked_scores for index in (v if isinstance(v, list) else [v]))\n",
    "            recall_results[j] += indicator\n",
    "            partial_recall_results[parts.index(query_labels[int(k)])][j] += indicator\n",
    "    \n",
    "    final_results = [result / len(key_ref) for result in recall_results]\n",
    "    print(\"Overall:\", \"; \".join(f\"Recall@{thresh}: {round(final_results[i],3)}\" for i, thresh in enumerate(recall_threshold)))\n",
    "\n",
    "def create_embeddings(tokenizer, model, texts):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    batch_size = 17\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(**inputs).pooler_output\n",
    "            embeddings.extend(batch_embeddings.cpu().tolist())\n",
    "\n",
    "    return embeddings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
